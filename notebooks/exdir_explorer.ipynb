{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import os.path as path\n",
    "import random\n",
    "from IPython.display import HTML\n",
    "\n",
    "import exdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import skvideo\n",
    "import yaml\n",
    "\n",
    "from cow_tus.analysis.visualizations.viewer import play\n",
    "import cow_tus.data.transforms.preprocessing as transforms\n",
    "\n",
    "os.chdir('/home/Gangus/cow-tus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_dataset = file['unprocessed']\n",
    "# main_dataset.create_group('train')\n",
    "# main_dataset.create_group('valid')\n",
    "# main_dataset.create_group('test')\n",
    "# splits = list(dataset.keys())\n",
    "# for split in splits:\n",
    "#     split_dataset = main_dataset[split]\n",
    "#     for i in range(9):\n",
    "#         exam_id = f'LD{random.randint(0, 10)}{random.randint(0, 10)}'\n",
    "#         if exam_id in split_dataset:\n",
    "#             while exam_id in split_dataset:\n",
    "#                 exam_id = f'LD{random.randint(0, 10)}{random.randint(0, 10)}'\n",
    "#         else:\n",
    "#             dset = split_dataset.create_dataset(exam_id, data=np.random.rand(7,4,5))\n",
    "#             dset.attrs = {\n",
    "#                 'exam_id': exam_id,\n",
    "#                 'label': random.randint(0, 2)\n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = '/data/cow-tus-data/raw'\n",
    "out_dir = 'sample.exdir'\n",
    "group_dir = 'data/'\n",
    "\n",
    "hypothesis_conditions = ['single-instance-learning', 'temporal-subsample']\n",
    "f = exdir.File(out_dir)\n",
    "g = f.require_group(hypothesis_conditions[0])\n",
    "for hypothesis_condition in hypothesis_conditions[1:]:\n",
    "    g = g.require_group(hypothesis_condition)\n",
    "root_group = g\n",
    "\n",
    "preprocess_fns = [\n",
    "    {\n",
    "        'fn': 'resize_clip',\n",
    "        'args': {\n",
    "            'size': (210, 280)\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'fn': 'crop_clip_horizontally_by_proportion',\n",
    "        'args': {\n",
    "            'ratio': (0.25, 0.75)\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'fn': 'rgb_to_grayscale',\n",
    "        'args': {}\n",
    "    }\n",
    "]\n",
    "\n",
    "raw_attrs_df = pd.read_csv(path.join(raw_dir, 'labels.csv'))\n",
    "\n",
    "metadata = {\n",
    "    'config.raw_dir': raw_dir,\n",
    "    'config.out_dir': out_dir,\n",
    "    'config.hypothesis_conditions': hypothesis_conditions,\n",
    "    'binary.num_normals': 0,\n",
    "    'binary.num_abnormals': 0,\n",
    "    'multiclass.num_0': 0,\n",
    "    'multiclass.num_1': 0,\n",
    "    'multiclass.num_2': 0,\n",
    "    'multiclass.num_3': 0,\n",
    "    'meta.num_loops': 0,\n",
    "    'meta.num_exams': 0\n",
    "}\n",
    "out_attrs_data = []\n",
    "for i, row in tqdm(raw_attrs_df.iterrows(), total=len(raw_attrs_df)):\n",
    "    attrs = dict(row)\n",
    "    tus_score = attrs['tus_score']\n",
    "    if tus_score == 'control':\n",
    "        tus_score = 1\n",
    "    global_label_binary = 0 if int(tus_score) == 1 else 1\n",
    "    global_label_multiclass = int(tus_score) - 1\n",
    "    \n",
    "    if global_label_binary == 0:\n",
    "        metadata['binary.num_normals'] += 1\n",
    "        metadata['multiclass.num_0'] += 1\n",
    "    else:\n",
    "        metadata['binary.num_abnormals'] += 1\n",
    "        if global_label_multiclass == 1:\n",
    "            metadata['multiclass.num_1'] += 1\n",
    "        elif global_label_multiclass == 2:\n",
    "            metadata['multiclass.num_2'] += 1\n",
    "        elif global_label_multiclass == 3:\n",
    "            metadata['multiclass.num_3'] += 1\n",
    "            \n",
    "    exam_id = attrs['id']\n",
    "    exam_path = os.path.join(raw_dir, 'exams', exam_id)\n",
    "    \n",
    "    exam_group = root_group.require_group(str(exam_id))\n",
    "    exam_group.attrs.update(attrs)\n",
    "    exam_group.attrs.update({\n",
    "        'exam_name': exam_id,\n",
    "        'exam_path': exam_path,\n",
    "        'global_label_binary': global_label_binary,\n",
    "        'global_label_multiclass': global_label_multiclass\n",
    "    })\n",
    "    \n",
    "    concat = []\n",
    "    for loop_name in os.listdir(exam_path):\n",
    "        loop_name = loop_name[:loop_name.rfind('.AVI')].replace(\" \", \"\")\n",
    "        loop_path = os.path.join(loops_dir, loop_name)\n",
    "        print(loop_path)\n",
    "#         loop = skvideo.io.vread(path.join(loops_dir, loop_name))\n",
    "#         for preprocess_fn in preprocess_fns:\n",
    "#             fn = preprocess_fn['fn']\n",
    "#             args = preprocess_fn['args']\n",
    "#             loop = getattr(transforms, fn)(loop, **args)\n",
    "        loop = np.random.rand(50, 28, 28)\n",
    "        loop_shape = loop.shape\n",
    "        loop_dataset = exam_group.require_dataset(loop_name, data=loop)\n",
    "        loop_dataset.attrs.update({\n",
    "            'loop_name': loop_name,\n",
    "            'loop_path': loop_path,\n",
    "            'loop_data_path': path.join(loop_dataset.directory, 'data.npy'),\n",
    "            'depth': loop_shape[0],\n",
    "            'height': loop_shape[1],\n",
    "            'width': loop_shape[2],\n",
    "            'channels': 1,\n",
    "        })\n",
    "        out_attrs_entry = {}\n",
    "        out_attrs_entry.update(exam_group.attrs)\n",
    "        out_attrs_entry.update(loop_dataset.attrs)\n",
    "        out_attrs_data.append(out_attrs_entry)\n",
    "    if i == 10:\n",
    "        break\n",
    "out_attrs_df = pd.DataFrame(out_attrs_data)\n",
    "out_attrs_df.to_csv(path.join(group_dir, 'attrs.csv'), index=False)\n",
    "with open(path.join(group_dir, 'metadata.yaml'), 'w') as f:\n",
    "    f.write(yaml.dump(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anim = play(loop)\n",
    "# HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(root_group.directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
