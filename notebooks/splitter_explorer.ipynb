{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import os.path as path\n",
    "import random\n",
    "from IPython.display import HTML\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "import exdir\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import skvideo\n",
    "import yaml\n",
    "\n",
    "os.chdir('/home/Gangus/cow-tus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/single-instance-learning/temporal-downsample'\n",
    "\n",
    "hypothesis_conditions = ['by-animal-number', 'hold-out-validation']\n",
    "group_dir = path.join('data', 'split', *hypothesis_conditions)\n",
    "\n",
    "split_counts = {\n",
    "    'train': 0, # will be replaced in the next line\n",
    "    'valid': 15,\n",
    "    'test': 15\n",
    "}\n",
    "split_counts['train'] = len(pd.read_csv(path.join(data_dir, 'attrs.csv'), index_col=0).index.unique()) - sum(split_counts.values())\n",
    "\n",
    "strata_key = 'raw.animal_number'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs_path = path.join(data_dir, 'attrs.csv')\n",
    "attrs_df = pd.read_csv(attrs_path, index_col=0)\n",
    "\n",
    "labels = []\n",
    "exam_groups = attrs_df.groupby('exdir.exam_id')\n",
    "for exam_id, exam_group in exam_groups:\n",
    "    labels.append(list(set(exam_group['preprocessed.global_label_multiclass']))[0])\n",
    "label_freqs = sorted(Counter(labels).items())\n",
    "\n",
    "split_to_quota = defaultdict(dict)\n",
    "for label, freq in label_freqs:\n",
    "    for split, count in split_counts.items():\n",
    "        split_to_quota[split][label] = int((count / len(exam_groups)) * freq)\n",
    "\n",
    "metadata_path = path.join(group_dir, 'metadata.yaml')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    f.write(yaml.dump({'meta.estimated_counts': dict(split_to_quota)}))\n",
    "\n",
    "animal_groups = attrs_df.groupby(strata_key)\n",
    "\n",
    "animal_id_to_exam_ids = defaultdict(list)\n",
    "for animal_id, animal_group in animal_groups:\n",
    "    exam_ids = set(animal_group.index)\n",
    "    animal_id_to_exam_ids[animal_id] += list(exam_ids)\n",
    "    \n",
    "animal_id_to_exam_ids = list(animal_id_to_exam_ids.items())\n",
    "random.shuffle(animal_id_to_exam_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_to_exam_ids = defaultdict(list)\n",
    "i = 0\n",
    "for split, count in split_counts.items():\n",
    "    added = 0\n",
    "    while added < count:\n",
    "        animal_id, exam_ids = animal_id_to_exam_ids[i]\n",
    "        split_to_exam_ids[split] += exam_ids\n",
    "        added += len(exam_ids)\n",
    "        i += 1\n",
    "    if count == -1:\n",
    "        exam_ids_remaining = list(zip(*animal_id_to_exam_ids[i:]))[1]\n",
    "        split_to_exam_ids[split] = [exam_id for exam_ids in exam_ids_remaining for exam_id in exam_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_to_labels = defaultdict(list)\n",
    "for split, exam_ids in split_to_exam_ids.items():\n",
    "    exam_groups = attrs_df.loc[exam_ids].groupby('exdir.exam_id')\n",
    "    for exam_id, exam_group in exam_groups:\n",
    "        split_to_labels[split].append(list(set(exam_group['preprocessed.global_label_multiclass']))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [(0, 20), (1, 17), (2, 10), (3, 9)]\n",
      "valid [(0, 4), (1, 3), (2, 5), (3, 3)]\n",
      "test [(0, 10), (1, 1), (2, 2), (3, 2)]\n"
     ]
    }
   ],
   "source": [
    "for split, labels in split_to_labels.items():\n",
    "    print(split, sorted(Counter(labels).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15/85 * "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
